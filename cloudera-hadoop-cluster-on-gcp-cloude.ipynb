{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Part 1 gcp Instance creation]\n",
    "\n",
    "Follow this google link to create Service account key and select json format.\n",
    "https://cloud.google.com/docs/authentication/getting-started\n",
    "\n",
    "And set this variable\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/path_to_json_file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install google python api client packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing  gcp libraries and setting up credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "import googleapiclient.discovery\n",
    "from six.moves import input\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/sathish/gcp_pem.json'\n",
    "compute = googleapiclient.discovery.build('compute', 'v1')\n",
    "project=\"ferrous-weaver-249914\"\n",
    "zone=\"us-east1-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data nodes and master node definition\n",
    "\n",
    "Refer Google page https://cloud.google.com/vpc/docs/vpc to find out default network internal Ipaddress range for your selected region\n",
    "\n",
    "Ex. us-east1\t10.142.0.0/20\t10.142.0.1\t10.142.0.2 to 10.142.15.253\n",
    "\n",
    "## Select machine types \n",
    "\n",
    "https://cloud.google.com/compute/docs/machine-types\n",
    "\n",
    "n1-standard-1\t1\t3.75\t128\t257\tYes\t2\n",
    "n1-standard-2\t2\t7.50\t128\t257\tYes\t10\n",
    "n1-standard-4\t4\t15\t128\t257\tYes\t10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_size=\"n1-standard-2\"\n",
    "data_node_instances={'datanode1':{'instance_name':'datanode1','hostname':'datanode1.tanu.com','networkIP':'10.142.15.199','script_template':'cloudera_datanode.sh'},\n",
    "                   'datanode2':{'instance_name':'datanode2','hostname':'datanode2.tanu.com','networkIP':'10.142.15.200','script_template':'cloudera_datanode.sh'},\n",
    "                   'datanode3':{'instance_name':'datanode3','hostname':'datanode3.tanu.com','networkIP':'10.142.15.201','script_template':'cloudera_datanode.sh'}}\n",
    "\n",
    "master_node_instances={'masternode1':{'instance_name':'masternode','hostname':'master.tanu.com','networkIP':'10.142.15.198','script_template':'cloudera_manager.sh'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data_node_startup_scripts(master_node_name,master_node_ip,script_template):\n",
    "    \n",
    "    script = open('new-client-startup-script.sh', 'w') \n",
    "    for masternode in master_node_instances:\n",
    "        networkIP=master_node_instances[masternode]['networkIP']\n",
    "        hostname=master_node_instances[masternode]['hostname']\n",
    "        print(\"echo {networkIP} {hostname}>>/etc/hosts ##adding Masternode host\".format(networkIP=networkIP,hostname=hostname),file=script)\n",
    "    for datanode in data_node_instances:\n",
    "        networkIP=data_node_instances[datanode]['networkIP']\n",
    "        hostname=data_node_instances[datanode]['hostname']\n",
    "        print(\"echo {networkIP} {hostname}>>/etc/hosts ##adding Data host\".format(networkIP=networkIP,hostname=hostname),file=script)\n",
    "    \n",
    "    print('''\n",
    "    #!/bin/bash\n",
    "\n",
    "    WORK_DIR=\"/var/tmp/startup_dir\"\n",
    "    \n",
    "    mkdir $WORK_DIR\n",
    "    cd $WORK_DIR\n",
    "    hostname=$(hostname -f)\n",
    "    #echo \"{master_node_ip} {master_node_name}\" >>/etc/hosts\n",
    "    yum -y install git-core net-tools krb5-workstation\n",
    "    git clone https://github.com/skumarx87/openldap_MIT-Kerberos_installation.git\n",
    "    cd openldap_MIT-Kerberos_installation\n",
    "    sed -i \"s/idm.tanu.com/{master_node_name}/g\" kerberos_ldap_installation.sh\n",
    "    ./kerberos_ldap_installation.sh client_setup |tee -a kerberos_install.log\n",
    "    sh {script_template} {master_node_name}|tee -a cm_agent_install.log\n",
    "    '''.format(master_node_ip=master_node_ip,master_node_name=master_node_name,script_template=script_template),file=script)\n",
    "\n",
    "    script.close()\n",
    "\n",
    "def generate_master_node_startup_scripts(master_node_name,script_template):\n",
    "    script = open('new-server-startup-script.sh', 'w') \n",
    "    \n",
    "    for masternode in master_node_instances:\n",
    "        networkIP=master_node_instances[masternode]['networkIP']\n",
    "        hostname=master_node_instances[masternode]['hostname']\n",
    "        print(\"echo {networkIP} {hostname}>>/etc/hosts ##adding Masternode host\".format(networkIP=networkIP,hostname=hostname),file=script)\n",
    "    for datanode in data_node_instances:\n",
    "        networkIP=data_node_instances[datanode]['networkIP']\n",
    "        hostname=data_node_instances[datanode]['hostname']\n",
    "        print(\"echo {networkIP} {hostname}>>/etc/hosts ##adding Data host\".format(networkIP=networkIP,hostname=hostname),file=script)\n",
    "    \n",
    "    print('''\n",
    "    #!/bin/bash\n",
    "    WORK_DIR=\"/var/tmp/startup_dir\"\n",
    "    mkdir $WORK_DIR\n",
    "    cd $WORK_DIR\n",
    "    echo \"this is startup script\"\n",
    "    yum -y install git-core net-tools krb5-workstation\n",
    "    git clone https://github.com/skumarx87/openldap_MIT-Kerberos_installation.git\n",
    "    cd openldap_MIT-Kerberos_installation\n",
    "    sed -i \"s/idm.tanu.com/{master_node_name}/g\" kerberos_ldap_installation.sh\n",
    "    ./kerberos_ldap_installation.sh server_setup|tee -a kerberos_install.log\n",
    "    ./kerberos_ldap_installation.sh setup_webserver|tee -a kerberos_install.log\n",
    "    ./kerberos_ldap_installation.sh client_setup|tee -a kerberos_install.log\n",
    "    ./kerberos_ldap_installation.sh create_hadoop_users|tee -a kerberos_install.log\n",
    "    chmod 755 {script_template}\n",
    "    sh {script_template} |tee -a cm_install.log\n",
    "    sh cloudera_datanode.sh {master_node_name} |tee -a cm_agent_install.log\n",
    "\n",
    "    '''.format(master_node_name=master_node_name,script_template=script_template),file=script)\n",
    "    \n",
    "    script.close()\n",
    "    \n",
    "def list_instances():\n",
    "        result = compute.instances().list(project=project, zone=zone).execute()\n",
    "        return result['items'] if 'items' in result else None\n",
    "        # [END list_instances]\n",
    "\n",
    "def list_images():\n",
    "        request = compute.images().list(project=project).execute()\n",
    "        print(request)\n",
    "        #while request is not None:\n",
    "        #       response = request.execute()\n",
    "        #       print(response)\n",
    "                #for image in response['items']:\n",
    "                #       pprint(image)\n",
    "        #       request = compute.images().list_next(previous_request=request, previous_response=response)\n",
    "def list_disks():\n",
    "        request = compute.disks().list(project=project, zone=zone)\n",
    "        while request is not None:\n",
    "            response = request.execute()\n",
    "            for disk in response['items']:\n",
    "                pprint(disk)\n",
    "            request = service.disks().list_next(previous_request=request, previous_response=response)\n",
    "        \n",
    "        \n",
    "def get_instance_networkIP(instance):\n",
    "        request = compute.instances().get(project=project, zone=zone, instance=instance)\n",
    "        response = request.execute()\n",
    "        pprint(response)\n",
    "        host_ip=response['networkInterfaces'][0]['networkIP']\n",
    "        return host_ip\n",
    "def get_instance_networkNatIP(instance):\n",
    "        request = compute.instances().get(project=project, zone=zone, instance=instance)\n",
    "        response = request.execute()\n",
    "        #pprint(response)\n",
    "        nat_ip=response['networkInterfaces'][0]['accessConfigs'][0]['natIP']\n",
    "        return nat_ip\n",
    "def get_instance_metadata_fingerprint(instance):\n",
    "        request = compute.instances().get(project=project, zone=zone, instance=instance)\n",
    "        response = request.execute()\n",
    "        pprint(response)\n",
    "        fingerprint=response['metadata']['fingerprint']\n",
    "        return fingerprint\n",
    "    \n",
    "def delete_instance(instance_name):\n",
    "    request = compute.instances().delete(project=project, zone=zone, instance=instance_name)\n",
    "    response = request.execute()\n",
    "    pprint(response)\n",
    "    \n",
    "def create_instance(name,hostname,startup_script,networkIP):\n",
    "        image_response = compute.images().getFromFamily(project='centos-cloud', family='centos-7').execute()\n",
    "        source_disk_image = image_response['selfLink']\n",
    "        #machine_type = \"zones/%s/machineTypes/n1-standard-1\" % zone\n",
    "        machine_type = \"zones/{zone}/machineTypes/{machine_size}\".format(zone=zone,machine_size=machine_size)\n",
    "        startup_script = open(\n",
    "                os.path.join(\n",
    "                        os.path.abspath(''), startup_script), 'r').read()\n",
    "        config = {\n",
    "            'name': name,\n",
    "            'machineType': machine_type,\n",
    "            'hostname':hostname,\n",
    "            'disks': [\n",
    "                {\n",
    "                    'boot': True,\n",
    "                    'autoDelete': True,\n",
    "                    'initializeParams': {\n",
    "                        'sourceImage': source_disk_image,\n",
    "                        'diskSizeGb': 20,\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            # Specify a network interface with NAT to access the public\n",
    "            # internet.\n",
    "            'networkInterfaces': [{\n",
    "                'network': 'global/networks/default',\n",
    "                'networkIP':networkIP,\n",
    "                'accessConfigs': [\n",
    "                    {'type': 'ONE_TO_ONE_NAT', 'name': 'External NAT'}\n",
    "                ]\n",
    "            }],\n",
    "            'metadata': {\n",
    "            'items': [{\n",
    "                # Startup script is automatically executed by the\n",
    "                # instance upon startup.\n",
    "                'key': 'startup-script',\n",
    "                'value': startup_script\n",
    "            }]\n",
    "            }\n",
    "        }\n",
    "        return compute.instances().insert(project=project,zone=zone,body=config).execute()\n",
    "            \n",
    "def wait_for_operation(operation):\n",
    "    print('Waiting for operation to finish...')\n",
    "    while True:\n",
    "        result = compute.zoneOperations().get(\n",
    "            project=project,\n",
    "            zone=zone,\n",
    "            operation=operation).execute()\n",
    "\n",
    "        if result['status'] == 'DONE':\n",
    "            print(\"done.\")\n",
    "            if 'error' in result:\n",
    "                raise Exception(result['error'])\n",
    "            return result\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "def Create_hadoop_instaces(wait=True):\n",
    "        #compute = googleapiclient.discovery.build('compute', 'v1')\n",
    "        print(\"Creating Master node\")    \n",
    "                     \n",
    "        for masternode in master_node_instances:\n",
    "            inst_name=master_node_instances[masternode]['instance_name']\n",
    "            host_name=master_node_instances[masternode]['hostname']\n",
    "            networkIP=master_node_instances[masternode]['networkIP']\n",
    "            script_template=master_node_instances[masternode]['script_template']\n",
    "            generate_master_node_startup_scripts(host_name,script_template)\n",
    "            operation=create_instance(inst_name,host_name,'new-server-startup-script.sh',networkIP)\n",
    "            print(operation)\n",
    "            wait_for_operation(operation['name'])\n",
    "\n",
    "        master_node_inst_name=master_node_instances['masternode1']['instance_name']\n",
    "        master_node_host_name=master_node_instances['masternode1']['hostname']\n",
    "        master_node_ip=get_instance_networkIP(master_node_inst_name)\n",
    "        time.sleep(80) ## wait for master node startup script completion\n",
    "        for datanode in data_node_instances:\n",
    "            print(\"Creating Data Node : {}\".format(datanode))\n",
    "            inst_name=data_node_instances[datanode]['instance_name']\n",
    "            host_name=data_node_instances[datanode]['hostname']\n",
    "            networkIP=data_node_instances[datanode]['networkIP']\n",
    "            script_template=data_node_instances[datanode]['script_template']\n",
    "            generate_data_node_startup_scripts(master_node_host_name,master_node_ip,script_template)\n",
    "            operation=create_instance(inst_name,host_name,'new-client-startup-script.sh',networkIP)\n",
    "            wait_for_operation(operation['name'])\n",
    "            \n",
    "\n",
    "def remove_startup_script(wait=True):\n",
    "    \n",
    "    for masternode in master_node_instances:\n",
    "        inst_name=master_node_instances[masternode]['instance_name']\n",
    "        fingerprint_id=get_instance_metadata_fingerprint(inst_name)\n",
    "        metadata_body={'fingerprint': fingerprint_id,\n",
    "              \"items\": [\n",
    "            {\n",
    "              \"key\": \"startup-script\",\n",
    "              \"value\": \"echo startup-script\"\n",
    "            }]\n",
    "            }\n",
    "        request = compute.instances().setMetadata(project=project, zone=zone, instance=inst_name, body=metadata_body)\n",
    "        response = request.execute()\n",
    "        pprint(response)\n",
    "\n",
    "    for datanode in data_node_instances:\n",
    "        inst_name=data_node_instances[datanode]['instance_name']\n",
    "        fingerprint_id=get_instance_metadata_fingerprint(inst_name)\n",
    "        metadata_body={'fingerprint': fingerprint_id,\n",
    "              \"items\": [\n",
    "            {\n",
    "              \"key\": \"startup-script\",\n",
    "              \"value\": \"echo startup-script\"\n",
    "            }]\n",
    "            }\n",
    "        request = compute.instances().setMetadata(project=project, zone=zone, instance=inst_name, body=metadata_body)\n",
    "        response = request.execute()\n",
    "        pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting Firewall rule to allow cloudera manager port 7180 over the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_filrewall_rule(name,ports):\n",
    "    firewall_body={\n",
    "        'name':name,\n",
    "        'allowed':[\n",
    "            {\n",
    "                \"IPProtocol\":'tcp',\n",
    "                \"ports\":ports\n",
    "            }\n",
    "        ],\n",
    "        \"sourceRanges\": ['0.0.0.0/0']\n",
    "    }\n",
    "    request = compute.firewalls().insert(project=project, body=firewall_body)\n",
    "    response = request.execute()\n",
    "    pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "        Create_hadoop_instaces()\n",
    "        time.sleep(80)## wait for data node startup script completion\n",
    "        remove_startup_script()\n",
    "        insert_filrewall_rule(\"cloudera-manager-url\",[\"7180\"])\n",
    "        insert_filrewall_rule(\"name-node\",[\"9870\"])\n",
    "        insert_filrewall_rule(\"yarn-resource-node\",[\"8088\"])\n",
    "        insert_filrewall_rule(\"yarn-history-node\",[\"19888\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cm_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Part 2 Hadoop Cluster creation]\n",
    "This Section is for creating Hadoop cluster and Cloudera management services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_host = 'http://34.74.25.211'\n",
    "port = '7180'\n",
    "api_version = 'v30'\n",
    "\n",
    "api_url = api_host + ':' + port + '/api/' + api_version\n",
    "api_client = cm_client.ApiClient(api_url)\n",
    "\n",
    "cm_client.configuration.username = 'admin'\n",
    "cm_client.configuration.password = 'admin'\n",
    "cluster_name='Cluster 8'\n",
    "cdh_version='CDH6'\n",
    "hostname='master.tanu.com'\n",
    "\n",
    "##Services Mapping\n",
    "cluster_Services={'service_name':'hive','hosts':['datanode1.tanu.com'],'db_details':{'name':'test'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MGMT_SERVICES=[\"EVENTSERVER\", \"HOSTMONITOR\", \"ALERTPUBLISHER\", \"SERVICEMONITOR\",\"ACTIVITYMONITOR\"]\n",
    "#MGMT_SERVICES=[\"NAVIGATORMETADATASERVER\"]\n",
    "\n",
    "AMON_ROLE_CONFIG = {\n",
    "   'firehose_database_host':'master.tanu.com' + \":3306\",\n",
    "   'firehose_database_user':'amon',\n",
    "   'firehose_database_password':'amon',\n",
    "   'firehose_database_type':'mysql',\n",
    "   'firehose_database_name':'amon',\n",
    "   'firehose_heapsize':'314572800'\n",
    "}\n",
    "\n",
    "RMAN_ROLE_CONFIG = {\n",
    "   'headlamp_database_host': 'master.tanu.com'+\":7432\",\n",
    "   'headlamp_database_user': 'rman',\n",
    "   'headlamp_database_password': 'rman',\n",
    "   'headlamp_database_type': 'mysql',\n",
    "   'headlamp_database_name': 'rman',\n",
    "   'headlamp_heapsize': '215964392',\n",
    "}\n",
    "\n",
    "NAV_ROLE_CONFIG = {\n",
    "   'navigator_database_host': 'master.tanu.com'+\":7432\",\n",
    "   'navigator_database_user': 'nav',\n",
    "   'navigator_database_password': 'nav',\n",
    "   'navigator_database_type': 'mysql',\n",
    "   'navigator_database_name': 'nav',\n",
    "   'navigator_heapsize': '215964392',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import cm_client\n",
    "from cm_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import hashlib\n",
    "\n",
    "# create an instance of the API class\n",
    "api_client=cm_client.ApiClient(api_url)\n",
    "\n",
    "def create_cluster():\n",
    "    \n",
    "    cluster1={'items':[\n",
    "        {'name': cluster_name,\n",
    "         \"version\": cdh_version,\n",
    "        }\n",
    "        ]}\n",
    "    try:\n",
    "        api_instance = cm_client.ClustersResourceApi(api_client)\n",
    "        api_instance.create_clusters(body=cluster1);\n",
    "        api_instance.add_hosts(cluster_name,body=cm_client.ApiHostRefList(HOSTS_LIST))\n",
    "    #print(cluster)\n",
    "    #cluster.add_hosts(HOSTS_LIST)\n",
    "    #pprint(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling ClustersResourceApi->create_clusters: %s\\n\" % e)\n",
    "def get_host_resource(hostname):\n",
    "    api_instance = cm_client.HostsResourceApi(api_client)\n",
    "    #print(api_instance.read_hosts(view='summary'))\n",
    "    try:\n",
    "        api_host_response = [x for x in api_instance.read_hosts(view='summary').items\n",
    "                             if hostname == x.hostname]\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling HostsResourceApi->read_hosts: %s\\n\" % e)\n",
    "    #print(api_host_response)\n",
    "    return api_host_response[0]\n",
    "\n",
    "def add_mgmt_service():\n",
    "    amon_role_name = \"ACTIVITYMONITOR\"\n",
    "    service_name = 'mgmt'\n",
    "    service_type = 'MGMT'.upper()\n",
    "    hostname='master.tanu.com'\n",
    "    host_id = getattr(get_host_resource(hostname),'host_id', None)\n",
    "    services_instance = cm_client.MgmtServiceResourceApi(api_client)\n",
    "    mgmt_role_instance = cm_client.MgmtRolesResourceApi(api_client)\n",
    "    rcg_instance = cm_client.MgmtRoleConfigGroupsResourceApi(api_client)\n",
    "    print(mgmt_role_instance)\n",
    "    try:\n",
    "        print(\"Create a CMS service and its associated roles.\")\n",
    "        services_instance.setup_cms(body=cm_client.ApiService(name=service_name,\n",
    "                                                              type=service_type,\n",
    "                                                              display_name='Cloudera Management Service'))\n",
    "        role_list = []\n",
    "        for role_type in MGMT_SERVICES:\n",
    "            role_name = \"%s-%s-%s\" % (service_name, role_type, hashlib.md5(hostname.encode('utf-8')).hexdigest())\n",
    "            #print(host_id)\n",
    "            role_list.append({\"name\": role_name, \"type\": role_type, \"hostRef\": {\"hostId\": host_id}})\n",
    "        #print(role_list)\n",
    "        body = cm_client.ApiRoleList(role_list)\n",
    "        api_response = mgmt_role_instance.create_roles(body=body)\n",
    "        api_response = rcg_instance.read_role_config_groups()\n",
    "        for rcg in api_response.items:\n",
    "            print(rcg)\n",
    "            if rcg.role_type == 'ACTIVITYMONITOR':\n",
    "                activity_config=[]\n",
    "                tmp={activity_config.append({'name':key,'value':value}) for key,value in AMON_ROLE_CONFIG.items()}\n",
    "                print(tmp)\n",
    "                rcg_instance.update_config(rcg.name, message=None,\n",
    "                                           body=cm_client.ApiConfigList(\n",
    "                                               activity_config\n",
    "                                           ))                                       \n",
    "                                            \n",
    "            if rcg.role_type == 'REPORTMANAGER':\n",
    "                rmon_config = []\n",
    "                tmp={rmon_config.append({'name':key,'value':value}) for key,value in RMAN_ROLE_CONFIG.items()}\n",
    "                rcg_instance.update_config(rcg.name, message=None,\n",
    "                                           body=cm_client.ApiConfigList([\n",
    "                                               rmon_config\n",
    "                                            ]))\n",
    "            '''\n",
    "            if rcg.role_type == 'NAVIGATOR':\n",
    "                nav_config = []\n",
    "                tmp={nav_config.append({'name':key,'value':value}) for key,value in NAV_ROLE_CONFIG.items()}\n",
    "                rcg_instance.update_config(rcg.name, message=None,\n",
    "                                           body=cm_client.ApiConfigList([\n",
    "                                               nav_config\n",
    "                                            ]))\n",
    "            '''\n",
    "        services_instance.start_command()\n",
    "    except ApiException as e:\n",
    "        print(\"Exception: %s\\n\" % e)\n",
    "\n",
    "#create_cluster();\n",
    "add_mgmt_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment to delete all hadoop compute instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm_client.ApiConfigList([RMAN_ROLE_CONFIG])\n",
    "import json\n",
    "r=json.dumps(AMON_ROLE_CONFIG)\n",
    "loaded_r = json.loads(r)\n",
    "#q=[]\n",
    "#for key in AMON_ROLE_CONFIG:\n",
    "#    q.append({\"name\":key,\"value\":AMON_ROLE_CONFIG[key]})\n",
    "#print(json.dumps(q))\n",
    "\n",
    "#x={key: value for key, value in AMON_ROLE_CONFIG}\n",
    "#values = map(lambda key: AMON_ROLE_CONFIG[key], AMON_ROLE_CONFIG.keys())\n",
    "#print(values)\n",
    "u=[]\n",
    "x={u.append({'name':key,'value':i}) for key,i in AMON_ROLE_CONFIG.items()}\n",
    "print(json.dumps(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hadoop_instaces(wait=True):\n",
    "    for masternode in master_node_instances:\n",
    "        inst_name=master_node_instances[masternode]['instance_name']\n",
    "        delete_instance(inst_name)\n",
    "\n",
    "    for datanode in data_node_instances:\n",
    "        inst_name=data_node_instances[datanode]['instance_name']\n",
    "        delete_instance(inst_name)\n",
    "\n",
    "        \n",
    "delete_hadoop_instaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_entry_details():\n",
    "    for masternode in master_node_instances:\n",
    "        inst_name=master_node_instances[masternode]['instance_name']\n",
    "        hostname=master_node_instances[masternode]['hostname']\n",
    "        nat_ip=get_instance_networkNatIP(inst_name)\n",
    "        print(\"{nat_ip} {hostname}\".format(nat_ip=nat_ip,hostname=hostname))\n",
    "\n",
    "    for datanode in data_node_instances:\n",
    "        inst_name=data_node_instances[datanode]['instance_name']\n",
    "        hostname=data_node_instances[datanode]['hostname']\n",
    "        nat_ip=get_instance_networkNatIP(inst_name)\n",
    "        print(\"{nat_ip} {hostname}\".format(nat_ip=nat_ip,hostname=hostname))\n",
    "\n",
    "get_host_entry_details()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
